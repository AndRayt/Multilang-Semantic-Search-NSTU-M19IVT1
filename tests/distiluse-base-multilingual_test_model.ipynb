{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('distiluse-base-multilingual-cased-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'/Users/arinatryaskova/Documents/quora_duplicate_questions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.is_duplicate == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['question1'].to_numpy()[:10000]\n",
    "questions2 = df['question2'].to_numpy()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of cosine similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sentence similarity efficiency we use such approach: for each sentence in questions2 array, we build embedding with chosen model and then compare use approach to calculate the similarity between embedding of input string (from questions2 set) and embedding of \"ideal\" string (from corpus set). Then we calculate accurate metrics as the ratio of correct answers to entire length of corpus array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6245\n"
     ]
    }
   ],
   "source": [
    "# Query sentences:\n",
    "queries = questions2\n",
    "\n",
    "score_counter = 0\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 1\n",
    "for query, sentence in zip(queries, corpus):\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "    \n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        if corpus[idx] == sentence:\n",
    "            score_counter += 1\n",
    "        \n",
    "print(score_counter / len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of hnswlib algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating HNSWLIB index\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 512    #Size of embeddings\n",
    "top_k_hits = 1         #Output k hits\n",
    "\n",
    "index = hnswlib.Index(space = 'cosine', dim = embedding_size)\n",
    "\n",
    "print(\"Start creating HNSWLIB index\")\n",
    "index.init_index(max_elements = len(corpus_embeddings), ef_construction = 20, M = 2)\n",
    "\n",
    "index.add_items(corpus_embeddings, list(range(len(corpus_embeddings))))\n",
    "\n",
    "index.set_ef(50)  # ef should always be > top_k_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1769\n"
     ]
    }
   ],
   "source": [
    "queries = questions2\n",
    "\n",
    "score_counter = 0\n",
    "\n",
    "for query, sentence in zip(queries, corpus):\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    corpus_id, distance = index.knn_query(query_embedding, k=top_k_hits)\n",
    "    \n",
    "    if corpus[corpus_id] == sentence:\n",
    "        score_counter += 1\n",
    "        \n",
    "print(score_counter / len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of Annoy algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleneighbors import SimpleNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_index_questions1 = SimpleNeighbors(512, metric='dot')\n",
    "for i, item in enumerate(corpus):\n",
    "    emb = embedder.encode(item, convert_to_numpy=True)\n",
    "    #emb = embed([item,]).numpy()[0]\n",
    "    annoy_index_questions1.add_one(item, emb)\n",
    "annoy_index_questions1.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5094\n"
     ]
    }
   ],
   "source": [
    "score_counter = 0\n",
    "for i, question_test in enumerate(questions2):\n",
    "    \n",
    "    ret = annoy_index_questions1.nearest(embedder.encode(question_test, convert_to_numpy=True))[0]\n",
    "    if ret == corpus[i]:\n",
    "        score_counter += 1\n",
    "print(score_counter / len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
